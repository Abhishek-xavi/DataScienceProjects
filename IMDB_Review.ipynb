{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Review.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2f04ZNVxysxLANmAdQL1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek-xavi/DataScienceProjects/blob/main/IMDB_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMeYL9hmGn4"
      },
      "source": [
        "#IMPORTING LIBRARIES\n",
        "\n",
        "import pandas as pd                                         #library to read excel\n",
        "from imblearn.under_sampling import RandomUnderSampler      #Importing library to keep the sample size similar for every type of predictions\n",
        "from sklearn.model_selection import train_test_split        #To divide data into train and test sets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  #To convert Review Words to text for modelling purpose. We use TF,IDF method\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd_4yCSjmkpc",
        "outputId": "32d2728c-9e4a-4b2a-aca9-c22ad0842b71"
      },
      "source": [
        "#Storing dataset in dataframe\n",
        "df_review = pd.read_csv(r\"/content/IMDB Dataset.csv\")\n",
        "print(df_review)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJGfyOnVmW26",
        "outputId": "c226d8f7-83bc-4782-8d7b-342a6921f2e0"
      },
      "source": [
        "#The data frame has 50,000 rows. To train the model faster, we will split the data.\n",
        "#First split will have 9000 negative and 1000 positive\n",
        "\n",
        "df_positive = df_review[df_review['sentiment']=='positive'][:9000]\n",
        "df_negative = df_review[df_review['sentiment']=='negative'][:1000]\n",
        "\n",
        "df_review_imb = pd.concat( [df_positive, df_negative] )\n",
        "print(df_review_imb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 review sentiment\n",
            "0     One of the other reviewers has mentioned that ...  positive\n",
            "1     A wonderful little production. <br /><br />The...  positive\n",
            "2     I thought this was a wonderful way to spend ti...  positive\n",
            "4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5     Probably my all-time favorite movie, a story o...  positive\n",
            "...                                                 ...       ...\n",
            "2000  Stranded in Space (1972) MST3K version - a ver...  negative\n",
            "2005  I happened to catch this supposed \"horror\" fli...  negative\n",
            "2007  waste of 1h45 this nasty little film is one to...  negative\n",
            "2010  Warning: This could spoil your movie. Watch it...  negative\n",
            "2013  Quite what the producers of this appalling ada...  negative\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LfWy38VnI3b",
        "outputId": "71fc5d7e-df80-494d-ae37-783641b3f08f"
      },
      "source": [
        "#Our data is Imbalanced as there are more positives than negatives\n",
        "\n",
        "#Calculating length of negative reviews\n",
        "length_negative = len(df_review_imb[df_review_imb['sentiment']=='negative'])\n",
        "#TAking only positive reviews equal to negative\n",
        "df_review_positive = df_review_imb[df_review_imb['sentiment']=='positive'].sample(n=length_negative)\n",
        "#Taking negative values\n",
        "df_review_non_positive = df_review_imb[~(df_review_imb['sentiment']=='positive')]\n",
        "#Concatanating to make a balance DataFrame\n",
        "df_review_bal = pd.concat([\n",
        "df_review_positive, df_review_non_positive\n",
        "])\n",
        "df_review_bal.reset_index(drop=True, inplace=True)\n",
        "df_review_bal['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    1000\n",
              "negative    1000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9wVz1kVvV9a"
      },
      "source": [
        "Usually before splitting data into train and test sets, we should clean the data. In this example, the data is already cleaned; however, real-world data is dirty, so whenever you need to clean data check the guide below to learn the best practices of data cleaning in Python.bold text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pl0XM-4vdSV"
      },
      "source": [
        "train, test = train_test_split( df_review_bal, test_size = 0.33, random_state = 42 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRjtELHUwDF1"
      },
      "source": [
        "# train_x: Independent variables (review) that will be used to train the model. Since we specified test_size = 0.33, 67% of observations from the data will be used to fit the model.\n",
        "# train_y: Dependent variables (sentiment) or target label that need to be predicted by this model.\n",
        "# test_x: The remaining 33% of independent variables that will be used to make predictions to test the accuracy of the model.\n",
        "# test_y: Category labels that will be used to test the accuracy between actual and predicted categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecp7kWUYv7dl"
      },
      "source": [
        "train_x, train_y = train['review'], train['sentiment']\n",
        "test_x, test_y = test['review'], test['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPTX5B0HxOhR"
      },
      "source": [
        "Machine learning algorithms cannot work with raw text directly; the text must be converted into numbers. Specifically, vectors of numbers. This is called feature extraction or feature encoding.\n",
        "\n",
        "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
        "\n",
        "1. A vocabulary of known words.\n",
        "2. A measure of the presence of known words.\n",
        "\n",
        "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl2eWufMrZ3t"
      },
      "source": [
        "There are multiple ways to convert words to vectors. Also this is called BAg of words\n",
        "\n",
        "1. Vector count - where we calculate how many times a word is found in the docs. But unfotunately this becomes confusing with words like the, a, an, etc.\n",
        "2. To overcome this, we have methods like TF-IDF, where we give values to words based on the number of times they occur in the doc.\n",
        "\n",
        "We give this value by,\n",
        "vector value = Total frequency / Inverse Doc frequency\n",
        "\n",
        "IDF = log of {number of docs in your corpus divided by the number of docs in which this term appears}\n",
        "\n",
        "Also, stop_words parameter removes all english connecting/stop words and increases our computational effeciency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7PYDJk-wRoo",
        "outputId": "09bc7cec-5221-49d9-ee1a-1df7c79be2f2"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "train_x_vector = tfidf.fit_transform(train_x)\n",
        "train_x_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1340x20494 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 118051 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "16IKJ1tdx0aV",
        "outputId": "ca002f9e-a4fc-4239-e249-9f0cd79fe59f"
      },
      "source": [
        "#To view the Sparse matrix\n",
        "pd.DataFrame.sparse.from_spmatrix(train_x_vector,\n",
        "                                  index=train_x.index,\n",
        "                                  columns=tfidf.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>07</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>100th</th>\n",
              "      <th>101</th>\n",
              "      <th>105</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>1242</th>\n",
              "      <th>13</th>\n",
              "      <th>134</th>\n",
              "      <th>13th</th>\n",
              "      <th>14</th>\n",
              "      <th>140</th>\n",
              "      <th>1470</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>157</th>\n",
              "      <th>15ft</th>\n",
              "      <th>15mins</th>\n",
              "      <th>16</th>\n",
              "      <th>16mm</th>\n",
              "      <th>16th</th>\n",
              "      <th>17</th>\n",
              "      <th>1700</th>\n",
              "      <th>177</th>\n",
              "      <th>17th</th>\n",
              "      <th>18</th>\n",
              "      <th>180</th>\n",
              "      <th>1800</th>\n",
              "      <th>1816</th>\n",
              "      <th>1888</th>\n",
              "      <th>...</th>\n",
              "      <th>zenda</th>\n",
              "      <th>zenia</th>\n",
              "      <th>zenith</th>\n",
              "      <th>zenobia</th>\n",
              "      <th>zephyr</th>\n",
              "      <th>zero</th>\n",
              "      <th>zest</th>\n",
              "      <th>zeta</th>\n",
              "      <th>zhaan</th>\n",
              "      <th>zhang</th>\n",
              "      <th>ziegler</th>\n",
              "      <th>zimbalist</th>\n",
              "      <th>zinc</th>\n",
              "      <th>zindulka</th>\n",
              "      <th>zing</th>\n",
              "      <th>zingers</th>\n",
              "      <th>zippy</th>\n",
              "      <th>ziyi</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zoey</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombies</th>\n",
              "      <th>zombiez</th>\n",
              "      <th>zomcom</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoned</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zooming</th>\n",
              "      <th>zooms</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "      <th>zázvorková</th>\n",
              "      <th>æon</th>\n",
              "      <th>élan</th>\n",
              "      <th>être</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.107445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.18352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1340 rows × 20494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       00  000  007   01   02  ...  zzzzzzzzzzzzzzzzzz  zázvorková  æon  élan  être\n",
              "81    0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "915   0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "1018  0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "380   0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "1029  0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "...   ...  ...  ...  ...  ...  ...                 ...         ...  ...   ...   ...\n",
              "1130  0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "1294  0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "860   0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "1459  0.0  0.0  0.0  0.0  0.0  ...             0.18352         0.0  0.0   0.0   0.0\n",
              "1126  0.0  0.0  0.0  0.0  0.0  ...             0.00000         0.0  0.0   0.0   0.0\n",
              "\n",
              "[1340 rows x 20494 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6edIpTXyHQp"
      },
      "source": [
        "#Converting test set as well\n",
        "test_x_vector = tfidf.transform(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19WYhkTHyQMv"
      },
      "source": [
        "Model Selection\n",
        "Now that we have numerical data, we can experiment with different machine learning models and evaluate their accuracy.\n",
        "\n",
        "Since Our problem is supervised - classification problem, we use the below models,\n",
        "\n",
        "*   SVM\n",
        "*   Desicion Tree\n",
        "*   Naive Bayes\n",
        "*   Logistic regression\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_laf-02yTyB",
        "outputId": "e4677783-2233-4ae6-c263-23b2aa5da827"
      },
      "source": [
        "#SVM separates the data points on agraph. Depending on the number of features, the SVM boundary is either a line, plane or so on.\n",
        "#The points near the boundary/plane are called supporting vectors and help determine the boundary.\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(train_x_vector, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Dl6BpxzRIr"
      },
      "source": [
        "After fitting svc we can predict whether a review is positive or negative with the .predict() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd6Q2fdRzNNK",
        "outputId": "19aacf24-4b30-4852-f884-d7c6cfc4cfb0"
      },
      "source": [
        "print(svc.predict(tfidf.transform(['A great movie'])))\n",
        "print(svc.predict(tfidf.transform(['An excellent movie'])))\n",
        "print(svc.predict(tfidf.transform(['I did not like this movie at all'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive']\n",
            "['positive']\n",
            "['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs4zEMjAzk9R",
        "outputId": "bbaba638-b3fc-4ba3-8655-f3fccc3a94bb"
      },
      "source": [
        "#BAsed on various parameters we have a claassifying value and branch the tree out.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dec_tree = DecisionTreeClassifier()\n",
        "dec_tree.fit(train_x_vector, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGaYyYCCzuXA",
        "outputId": "b96af5fd-b84e-47ae-9558-b937befa7050"
      },
      "source": [
        "#BAsed on Bayes conditional probability theorem\n",
        "#https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(train_x_vector.toarray(), train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apna-zz6z5LV",
        "outputId": "109872ba-b712-46cf-f2f7-ac6e8f91d702"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(train_x_vector, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8EwEBH90CzK"
      },
      "source": [
        "Now we go forward to model evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkpDNLwz0eny",
        "outputId": "814611d5-c6a8-4282-bd07-d82178c91df1"
      },
      "source": [
        "# svc.score('Test samples', 'True labels')\n",
        "print('SVM:',round(svc.score(test_x_vector, test_y),2))\n",
        "print('Desicion Tree:',round(dec_tree.score(test_x_vector, test_y),2))\n",
        "print('Naive Bayes:',round(gnb.score(test_x_vector.toarray(), test_y),2))\n",
        "print('Logistic Regression:',round(log_reg.score(test_x_vector, test_y),2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM: 0.82\n",
            "Desicion Tree: 0.7\n",
            "Naive Bayes: 0.6\n",
            "Logistic Regression: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZURDkZb1QmI"
      },
      "source": [
        "F1 Score\n",
        "F1 Score is the weighted average of Precision and Recall. Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial. Also, F1 takes into account how the data is distributed, so it’s useful when you have data with imbalance classes.\n",
        "\n",
        "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "F1 score reaches its best value at 1 and worst score at 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuov2_R-1TaK",
        "outputId": "a5c788c8-baea-462f-b27b-9659efb059bb"
      },
      "source": [
        "#https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(test_y, svc.predict(test_x_vector),\n",
        "         labels=['positive', 'negative'],\n",
        "         average=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.81981982, 0.81651376])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6CQ0uLa2MTr",
        "outputId": "63290d87-0c67-4ae7-d930-89f77545cad8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_y, \n",
        "                            svc.predict(test_x_vector),\n",
        "                            labels=['positive', 'negative']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.80      0.84      0.82       325\n",
            "    negative       0.84      0.80      0.82       335\n",
            "\n",
            "    accuracy                           0.82       660\n",
            "   macro avg       0.82      0.82      0.82       660\n",
            "weighted avg       0.82      0.82      0.82       660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3J80mTR2W1p"
      },
      "source": [
        "Confusion Matrix\n",
        "A confusion matrix) is a table that allows visualization of the performance of an algorithm. This table typically has two rows and two columns that report the number of false positives, false negatives, true positives, and true negatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0a4mGuz2Xjf",
        "outputId": "6e44f8f5-3156-4bcc-b23c-1c0867f480ef"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(test_y, \n",
        "                            svc.predict(test_x_vector), \n",
        "                            labels=['positive', 'negative'])\n",
        "print(conf_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[273  52]\n",
            " [ 68 267]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkiDatg42tBo"
      },
      "source": [
        "To understand what that means check this picture below.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLIHZwCV3FSq"
      },
      "source": [
        "Now Let's work on Tuning the Model.\n",
        "We shall work on SVC but this time we introduce hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy7rjNjd20Fz",
        "outputId": "b5696269-eff6-4254-bb72-e08334edda2f"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#set the parameters\n",
        "parameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\n",
        "svc = SVC()\n",
        "svc_grid = GridSearchCV(svc,parameters, cv=5)\n",
        "\n",
        "svc_grid.fit(train_x_vector, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnBo1NZY4VLe",
        "outputId": "3e063e3a-be89-4f17-ed5d-188c2e79fc19"
      },
      "source": [
        "#After fitting the model, we obtain the best score, parameters, and estimators with the following code.\n",
        "\n",
        "print(svc_grid.best_params_)\n",
        "print(svc_grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 4, 'kernel': 'rbf'}\n",
            "SVC(C=4, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVG3gFUcPzsc"
      },
      "source": [
        "The biggest difference between the models you're building from a \"features\" point of view is that Naive Bayes treats them as independent, whereas SVM looks at the interactions between them to a certain degree, as long as you're using a non-linear kernel (Gaussian, rbf, poly etc.). So if you have interactions, and, given your problem, you most likely do, an SVM will be better at capturing those, hence better at the classification task you want."
      ]
    }
  ]
}